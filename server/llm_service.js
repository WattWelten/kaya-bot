const axios = require('axios');

class LLMService {
    constructor() {
        // Umgebungsvariablen direkt aus process.env laden
        this.openaiApiKey = process.env.OPENAI_API_KEY;
        this.elevenlabsApiKey = process.env.ELEVENLABS_API_KEY;
        this.openaiBaseUrl = process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1';
        
        console.log('ðŸ”§ LLM Service initialisiert:');
        console.log('  - OpenAI API Key:', this.openaiApiKey ? 'VORHANDEN âœ…' : 'FEHLT âŒ');
        console.log('  - ElevenLabs API Key:', this.elevenlabsApiKey ? 'VORHANDEN âœ…' : 'FEHLT âŒ');
    }

    async generateTextResponse(prompt, context = '') {
        try {
            const response = await axios.post(`${this.openaiBaseUrl}/chat/completions`, {
                model: 'gpt-4o-mini', // KostengÃ¼nstig fÃ¼r Produktion
                messages: [
                    {
                        role: 'system',
                        content: this.getSystemPrompt(context)
                    },
                    {
                        role: 'user',
                        content: prompt
                    }
                ],
                max_tokens: 500,
                temperature: 0.7,
                presence_penalty: 0.1,
                frequency_penalty: 0.1
            }, {
                headers: {
                    'Authorization': `Bearer ${this.openaiApiKey}`,
                    'Content-Type': 'application/json'
                }
            });

            return response.data.choices[0].message.content;
        } catch (error) {
            console.error('OpenAI API Fehler:', error.response?.data || error.message);
            throw new Error('LLM-Service nicht verfÃ¼gbar');
        }
    }

    async transcribeAudio(audioBuffer) {
        try {
            const FormData = require('form-data');
            const form = new FormData();
            
            // Erstelle eine temporÃ¤re Datei fÃ¼r das Audio
            form.append('file', audioBuffer, {
                filename: 'audio.wav',
                contentType: 'audio/wav'
            });
            form.append('model', 'whisper-1');
            form.append('language', 'de');
            form.append('response_format', 'verbose_json');

            const response = await axios.post(`${this.openaiBaseUrl}/audio/transcriptions`, form, {
                headers: {
                    'Authorization': `Bearer ${this.openaiApiKey}`,
                    ...form.getHeaders()
                }
            });

            return {
                text: response.data.text,
                confidence: response.data.segments?.[0]?.avg_logprob || 0.9
            };
        } catch (error) {
            console.error('Whisper API Fehler:', error.response?.data || error.message);
            throw new Error('Audio-Transkription fehlgeschlagen');
        }
    }

    async generateAudioResponse(text, voiceId = 'otF9rqKzRHFgfwf6serQ') { // KAYA Voice ID
        try {
            const response = await axios.post(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`, {
                text: text,
                model_id: 'eleven_flash_v2_5',
                voice_settings: {
                    stability: 0.5,
                    similarity_boost: 0.5,
                    style: 0.0,
                    use_speaker_boost: true
                }
            }, {
                headers: {
                    'xi-api-key': this.elevenlabsApiKey,
                    'Content-Type': 'application/json'
                },
                responseType: 'arraybuffer'
            });

            return Buffer.from(response.data);
        } catch (error) {
            console.error('ElevenLabs API Fehler:', error.response?.data || error.message);
            throw new Error('Audio-Service nicht verfÃ¼gbar');
        }
    }

    getSystemPrompt(context) {
        return `Du bist KAYA, der kommunale KI-Assistent des Landkreises Oldenburg.

PERSÃ–NLICHKEIT:
- Norddeutsch-freundlich und empathisch
- BÃ¼rgerzentriert und hilfsbereit
- Professionell aber nahbar
- Verwendet "Moin" als GruÃŸ

AUFGABEN:
- Beantwortung von BÃ¼rgeranfragen basierend auf verfÃ¼gbaren Daten
- Hilfestellung bei Verwaltungsangelegenheiten
- Bereitstellung von konkreten Kontakten und Formularen
- ErklÃ¤rung von Prozessen mit nÃ¤chsten Schritten

VERFÃœGBARE DATEN: ${context}

WICHTIG:
- Verwende NUR die verfÃ¼gbaren Daten aus dem Kontext
- ErwÃ¤hne konkrete Kontakte, Formulare und Links
- Gib praktische nÃ¤chste Schritte vor
- Sei spezifisch und hilfreich

ANTWORT-STIL:
- Kurz und prÃ¤zise
- Empathisch und verstÃ¤ndlich
- Mit konkreten nÃ¤chsten Schritten
- Ohne "Butter bei die Fische" Phrasen
- ErwÃ¤hne verfÃ¼gbare Formulare und Kontakte

        KRITISCHE LINK-REGELN - NIEMALS VERLETZEN:
        âš ï¸ ABSOLUT VERBOTEN: Link-Texte zu Ã¤ndern oder zu Ã¼berschreiben
        âš ï¸ ABSOLUT VERBOTEN: "[Landkreis-Services]" oder Ã¤hnliche generische Texte zu verwenden
        âœ… ERLAUBT: Nur die EXAKT bereitgestellten Link-Texte zu verwenden
        âœ… BEISPIEL: Wenn "[Antragsarten und Unterlagen]" bereitgestellt wird â†’ verwende EXAKT diesen Text
        âœ… BEISPIEL: Wenn "[Favoriten]" bereitgestellt wird â†’ verwende EXAKT diesen Text
        âœ… BEISPIEL: Wenn "[Eichenprozessionsspinner]" bereitgestellt wird â†’ verwende EXAKT diesen Text
        
        LINK-FORMAT: [BEREITGESTELLTER_TEXT](URL)
        - Markdown-Links fÃ¼r alle URLs: [Beschreibung](URL)
        - PDF-Dateien: [PDF: Dateiname](URL)
        - Telefonnummern: **Tel.: 04431 85-0**
        - E-Mails: **E-Mail: kontakt@landkreis-oldenburg.de**

Antworte immer auf Deutsch und im norddeutschen Ton.`;
    }

    async enhanceResponse(agentResponse, userQuery) {
        try {
            const context = this.buildContext(agentResponse);
            const enhancedText = await this.generateTextResponse(userQuery, context);
            
            return {
                ...agentResponse,
                response: enhancedText,
                originalResponse: agentResponse.response, // Original behalten
                enhanced: true,
                llmUsed: true,
                // Alle Agent-Daten beibehalten
                data: agentResponse.data,
                links: agentResponse.links,
                confidence: agentResponse.confidence,
                source: agentResponse.source
            };
        } catch (error) {
            console.error('LLM-Enhancement Fehler:', error);
            return agentResponse; // Fallback zur ursprÃ¼nglichen Antwort
        }
    }

    buildContext(agentResponse) {
        let context = `Agent: ${agentResponse.agent}\n`;
        
        if (agentResponse.data && agentResponse.data.length > 0) {
            context += `VerfÃ¼gbare Daten:\n`;
            agentResponse.data.forEach((item, index) => {
                context += `${index + 1}. ${item.title}\n`;
                
                // Content hinzufÃ¼gen
                if (item.content && item.content.length > 0) {
                    const contentPreview = item.content.substring(0, 200) + '...';
                    context += `   Inhalt: ${contentPreview}\n`;
                }
                
                // Kontakte hinzufÃ¼gen
                if (item.contacts && item.contacts.length > 0) {
                    context += `   Kontakte: ${item.contacts.map(c => c.value).join(', ')}\n`;
                }
                
                // Formulare hinzufÃ¼gen
                if (item.forms && item.forms.length > 0) {
                    context += `   Formulare: ${item.forms.map(f => f.title).join(', ')}\n`;
                }
            });
        }
        
        if (agentResponse.links && agentResponse.links.length > 0) {
            context += `Relevante Links:\n`;
            agentResponse.links.forEach((link, index) => {
                context += `${index + 1}. ${link.title}: ${link.url}\n`;
            });
        }
        
        return context;
    }
}

module.exports = LLMService;
