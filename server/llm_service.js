const axios = require('axios');
const costTracker = require('./services/cost_tracker');

/**
 * KAYA LLM Service - OpenAI Integration
 * 
 * Dieser Service integriert OpenAI f√ºr intelligente Antworten
 * mit Fallback auf lokale Templates bei Fehlern.
 */

class LLMService {
    constructor() {
        this.openaiApiKey = process.env.OPENAI_API_KEY;
        this.openaiApiUrl = 'https://api.openai.com/v1/chat/completions';
        this.model = 'gpt-4o-mini'; // Kostenoptimiertes Modell
        this.maxTokens = 120; // Balance: Voice-ready + Links m√∂glich
        this.temperature = 0.8; // Kreativer f√ºr pers√∂nlichere Antworten
        
        // Circuit Breaker f√ºr Fehlerbehandlung
        this.circuitBreaker = {
            isOpen: false,
            failureCount: 0,
            lastFailureTime: 0,
            timeout: 60000 // 1 Minute
        };
        
        console.log('ü§ñ LLM Service initialisiert (OpenAI aktiviert)');
    }
    
    /**
     * Generiert intelligente Antwort mit OpenAI
     * 
     * @param {string} query - Die Benutzeranfrage
     * @param {object} context - Kontext (Persona, Intention, etc.)
     * @returns {Promise<object>} - {response: string, success: boolean}
     */
    async generateResponse(query, context = {}) {
        try {
            // Circuit Breaker pr√ºfen
            if (this.circuitBreaker.isOpen) {
                if (Date.now() - this.circuitBreaker.lastFailureTime > this.circuitBreaker.timeout) {
                    this.circuitBreaker.isOpen = false;
                    this.circuitBreaker.failureCount = 0;
                    console.log('üîß Circuit Breaker: Geschlossen, versuche erneut');
                } else {
                    console.log('‚ö†Ô∏è Circuit Breaker: Offen, Fallback aktiviert');
                    return { response: null, success: false, reason: 'circuit_breaker' };
                }
            }
            
            // OpenAI API Call
            const response = await axios.post(
                this.openaiApiUrl,
                {
                    model: this.model,
                    messages: this.buildMessages(query, context),
                    max_tokens: this.maxTokens,
                    temperature: this.temperature,
                    top_p: 1,
                    frequency_penalty: 0,
                    presence_penalty: 0
                },
                {
                    headers: {
                        'Authorization': `Bearer ${this.openaiApiKey}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: 10000 // 10 Sekunden Timeout
                }
            );
            
            // Erfolgreiche Antwort
            this.circuitBreaker.isOpen = false;
            this.circuitBreaker.failureCount = 0;
            
            const aiResponse = response.data.choices[0].message.content;
            
            // Kosten tracken
            const inputTokens = response.data.usage.prompt_tokens;
            const outputTokens = response.data.usage.completion_tokens;
            costTracker.trackOpenAI(inputTokens, outputTokens);
            
            // Token-√ñkonomie pr√ºfen
            this.trackTokenEconomy(outputTokens, query);
            
            console.log('‚úÖ OpenAI Antwort erhalten:', aiResponse.substring(0, 100));
            
            return {
                response: aiResponse,
                success: true,
                usage: response.data.usage
            };
            
        } catch (error) {
            // Fehlerbehandlung
            this.handleError(error);
            return {
                response: null,
                success: false,
                reason: error.message
            };
        }
    }
    
    /**
     * Baut die Messages f√ºr OpenAI
     * 
     * @param {string} query - Die Benutzeranfrage
     * @param {object} context - Kontext
     * @returns {Array} - Messages f√ºr OpenAI
     */
    buildMessages(query, context) {
        const systemPrompt = this.buildSystemPrompt(context);
        const messages = [
            {
                role: 'system',
                content: systemPrompt
            }
        ];
        
        // NEU: Conversation History hinzuf√ºgen (letzte 5 Nachrichten)
        if (context.conversationHistory && context.conversationHistory.length > 0) {
            const history = context.conversationHistory.slice(-5); // Max. 5 f√ºr Token-Effizienz
            
            history.forEach(msg => {
                // Pr√ºfe ob Nachricht noch nicht aktuell ist (doppelte Vermeidung)
                if (msg.content && msg.content !== query) {
                    const role = msg.sender === 'user' ? 'user' : 'assistant';
                    messages.push({
                        role: role,
                        content: msg.content
                    });
                    console.log(`üìù History: ${role} - "${msg.content.substring(0, 50)}..."`);
                }
            });
            
            console.log(`üìù ${history.length} Historie-Nachrichten an LLM √ºbergeben`);
        }
        
        // Aktuelle Query hinzuf√ºgen
        messages.push({
            role: 'user',
            content: query
        });
        
        return messages;
    }
    
    /**
     * Erstellt System-Prompt f√ºr KAYA
     * 
     * @param {object} context - Kontext (Persona, Intention, etc.)
     * @returns {string} - System-Prompt
     */
    buildSystemPrompt(context) {
        const { persona, emotionalState, urgency, language = 'german', userData, isFirstMessage } = context;
        
        // PERFEKTER MENSCHLICHER DIALOG - BESTER KOMMUNAL-AVATAR
        let prompt = `Du bist KAYA - die digitale Assistentin vom Landkreis Oldenburg.

üéØ DEIN AUFTRAG:
F√ºhre einen nat√ºrlichen Dialog wie eine echte Rezeptionistin.

üí¨ DIALOG-PRINZIPIEN:
1. Bei unklaren Fragen: NACHFRAGEN statt raten
   - User: "Ich brauche ein Auto"
   - Du: "M√∂chtest du ein Auto zulassen, abmelden oder erstmal Infos?"

2. Bei klaren Fragen: DIREKTE L√ñSUNG
   - User: "Auto zulassen"
   - Du: "Klar! Termin buchst du hier: [Link](URL)"

3. IMMER kontextbewusst:
   - Beziehe dich auf vorherige Nachrichten
   - Nutze Namen wenn bekannt
   - Merke dir Themen

üìù ANTWORT-STRUKTUR:
- Best√§tigung (1 Satz)
- L√∂sung ODER Nachfrage (2-3 S√§tze)
- Link (wenn relevant)
- Abschlussfrage (1 Satz)

üîó LINKS (KORREKT - NUR DIESE!):
- KFZ: https://www.oldenburg-kreis.de/fuehrerscheinstelle/
- Jobcenter: https://www.oldenburg-kreis.de/wirtschaft-und-arbeit/jobcenter-landkreis-oldenburg/
- Bauantr√§ge: https://www.oldenburg-kreis.de/planen-und-bauen/bauen-im-landkreis-oldenburg/antraege-und-formulare/
- B√ºrgerdienste: https://www.oldenburg-kreis.de/
- Kreistag: https://oldenburg-kreis.ratsinfomanagement.net/sitzungen/

WICHTIG: IMMER einen dieser Links nutzen. KEINE erfundenen URLs!

üí¨ TON:
- Umgangssprachlich: "klar", "gerne", "genau"
- Kurz & pr√§zise (max. 80 W√∂rter)
- Pers√∂nlich & menschlich

üö® SICHERHEIT:
- Keine Rechtsberatung
- Notf√§lle: SOFORT 112/110 nennen`;

        // User-Kontext
        if (userData && userData.name) {
            prompt += `\n\nüë§ Der Nutzer hei√üt ${userData.name}. Nutze den Namen NAT√úRLICH und PERSONLICH.`;
        }
        
        // Conversation History
        if (context.conversationHistory && context.conversationHistory.length > 1) {
            prompt += `\n\nüìù Du kennst die vorherige Nachricht. Antworte KOH√ÑRENT und beziehe dich auf den Kontext.`;
        }
        
        // Erste Nachricht
        if (isFirstMessage) {
            prompt += `\n\nüéØ Erste Nachricht: Beginne mit "Moin!" dann eine Frage "Wie kann ich helfen?"`;
        } else {
            prompt += `\n\nüéØ KEINE Begr√º√üung - direkt zur Antwort.`;
        }
        
        prompt += `\n\nJETZT: Antworte auf die Anfrage. Bei Unklarheit: NACHFRAGEN.`;

        // Persona-spezifische Anpassungen
        if (persona && persona.persona) {
            const personaPrompts = {
                'unemployed': 'Der B√ºrger ist arbeitslos/arbeitssuchend - sei besonders respektvoll, ermutigend und ressourcenorientiert. Zeige Verst√§ndnis f√ºr schwierige Lebenslagen.',
                'unemployed_longterm': 'Der B√ºrger ist langzeitarbeitslos - sei besonders empathisch, geduldig und l√∂sungsorientiert. Biete konkrete Hilfsangebote an.',
                'senior': 'Der B√ºrger ist Senior - verwende einfache Sprache, keine Anglizismen, mehr Zeit f√ºr Erkl√§rungen. Stelle sicher, dass alles verstanden wurde.',
                'senior_active': 'Der B√ºrger ist aktiver Senior - verwende klare, direkte Sprache. Biete optionale Details an.',
                'disabled': 'Der B√ºrger hat eine Behinderung - sei praktisch und l√∂sungsorientiert. Frage nach Bedarfen, nicht nach Einschr√§nkungen.',
                'disabled_worker': 'Der B√ºrger hat eine Behinderung im Arbeitsleben - fokussiere auf Teilhabe-M√∂glichkeiten und Unterst√ºtzungsangebote.',
                'migrant': 'Der B√ºrger ist Migrant - verwende einfache Sprache, kurze S√§tze, kulturelle Sensibilit√§t. Erkl√§re Verwaltungsprozesse besonders klar.',
                'family': 'Der B√ºrger kommt mit Familie - ber√ºcksichtige Bed√ºrfnisse von Kindern und Eltern.',
                'entrepreneur': 'Der B√ºrger ist Unternehmer/Gr√ºnder - fokussiere auf Wirtschaftsf√∂rderung, F√∂rdermittel, Gr√ºndungsberatung.',
                'political_interested': 'Der B√ºrger interessiert sich f√ºr Politik - biete Details zu Kreistag, Fraktionen, Gremien, Vorlagen.',
                'tourist': 'Der B√ºrger ist Tourist - sei einladend, fokussiere auf Sehensw√ºrdigkeiten, Kultur, Unterk√ºnfte.',
                'farmer': 'Der B√ºrger ist Landwirt - kenne die spezifischen Bedarfe (EU-F√∂rderung, Tierhaltung, Agrarstruktur).',
                'student': 'Der B√ºrger ist Student - fokussiere auf Hochschulen, BAf√∂G, Semesterticket, Studienfinanzierung.',
                'craftsman': 'Der B√ºrger ist Handwerker - kenne Handwerkskammer, Meisterpr√ºfung, Ausbildungsordnungen.',
                'pensioner': 'Der B√ºrger ist Rentner - fokussiere auf Rente, Altersvorsorge, Seniorenberatung.',
                'single_parent': 'Der B√ºrger ist Alleinerziehend - ber√ºcksichtige Kinderbetreuung, Unterhaltsvorschuss, Zeitdruck.',
                'small_business': 'Der B√ºrger ist Kleinunternehmer - fokussiere auf Gewerbe, Steuern, F√∂rdermittel.',
                'child': 'Der B√ºrger ist Kind/Sch√ºler - verwende einfache, freundliche Sprache, erkl√§re Verwaltungsabl√§ufe kindgerecht.',
                'care_dependent': 'Der B√ºrger ist pflegebed√ºrftig - fokussiere auf Pflegeleistungen, Pflegedienste, Eingliederungshilfe.',
                'low_income': 'Der B√ºrger hat niedriges Einkommen - zeige alle verf√ºgbaren Unterst√ºtzungsangebote auf.'
            };
            
            const personaPrompt = personaPrompts[persona.persona] || `Der B√ºrger ist ${persona.persona}`;
            prompt += `\n\nPERSONA KONTEXT: ${personaPrompt}`;
        }
        
        // Emotionale Zust√§nde
        if (emotionalState && emotionalState.state) {
            const emotionPrompts = {
                frustrated: 'Der B√ºrger ist frustriert - sei besonders empathisch und l√∂sungsorientiert. Zeige Verst√§ndnis, biete sofort konkrete L√∂sungen.',
                anxious: 'Der B√ºrger ist unsicher - sei beruhigend und unterst√ºtzend. Erkl√§re Schritt f√ºr Schritt, nimm √Ñngste ernst.',
                positive: 'Der B√ºrger ist motiviert - sei enthusiastisch und best√§rkend. Biete proaktive Unterst√ºtzung.',
                neutral: 'Der B√ºrger ist neutral - sei professionell und hilfreich.',
                urgent: 'Der B√ºrger hat zeitlichen Druck - reagiere schnell und zielf√ºhrend, biete sofort L√∂sungen an.',
                confused: 'Der B√ºrger ist verwirrt - erkl√§re einfach und strukturiert, frage nach Verst√§ndnis.'
            };
            prompt += `\n\nEMOTIONALER ZUSTAND: ${emotionPrompts[emotionalState.state] || ''}`;
        }
        
        // Dringlichkeit
        if (urgency && urgency.level === 'critical') {
            prompt += `\n\nDRINGLICHKEIT: KRITISCH - Biete sofort Hilfe (Telefonnummer, Termine)`;
        }
        
        prompt += `\n\nANTWORTE JETZT auf die Anfrage. Sei konkret, hilfreich und norddeutsch.`;
        
        return prompt;
    }
    
    /**
     * Fehlerbehandlung mit Circuit Breaker
     * 
     * @param {Error} error - Der Fehler
     */
    handleError(error) {
        this.circuitBreaker.failureCount++;
        this.circuitBreaker.lastFailureTime = Date.now();
        
        // Bei 3 Fehlern: Circuit Breaker √∂ffnen
        if (this.circuitBreaker.failureCount >= 3) {
            this.circuitBreaker.isOpen = true;
            console.error('üî¥ Circuit Breaker: GE√ñFFNET nach 3 Fehlern');
        }
        
        // Log Fehler
        if (error.response) {
            console.error('‚ùå OpenAI API Fehler:', error.response.status, error.response.data);
        } else if (error.request) {
            console.error('‚ùå OpenAI API Fehler: Keine Antwort vom Server');
        } else {
            console.error('‚ùå OpenAI API Fehler:', error.message);
        }
    }
    
    /**
     * Pr√ºft ob Service verf√ºgbar ist
     * 
     * @returns {boolean}
     */
    isAvailable() {
        return !!this.openaiApiKey && !this.circuitBreaker.isOpen;
    }
    
    /**
     * Gibt Status zur√ºck
     * 
     * @returns {object}
     */
    getStatus() {
        return {
            available: this.isAvailable(),
            circuitBreakerOpen: this.circuitBreaker.isOpen,
            failureCount: this.circuitBreaker.failureCount,
            hasApiKey: !!this.openaiApiKey
        };
    }
    
    /**
     * Pr√ºft Token-√ñkonomie (Ziel: 80-220 Tokens)
     * 
     * @param {number} outputTokens - Anzahl Output-Tokens
     * @param {string} query - Query zur Kontext-Anzeige
     * @returns {object} - Metrics
     */
    trackTokenEconomy(outputTokens, query) {
        const target = { min: 40, max: 120 }; // Angepasst an neue maxTokens
        
        if (outputTokens < target.min) {
            console.warn(`‚ö†Ô∏è Antwort zu kurz: ${outputTokens} Tokens (Ziel: ${target.min}-${target.max})`);
        } else if (outputTokens > target.max) {
            console.warn(`‚ö†Ô∏è Antwort zu lang: ${outputTokens} Tokens (Ziel: ${target.min}-${target.max}) - Voice-unfriendly`);
        } else {
            console.log(`‚úÖ Token-√ñkonomie perfekt f√ºr Dialog: ${outputTokens} Tokens`);
        }
        
        // Metrics f√ºr Monitoring
        return {
            tokens: outputTokens,
            withinTarget: outputTokens >= target.min && outputTokens <= target.max,
            efficiency: (target.max - outputTokens) / target.max
        };
    }
}

module.exports = LLMService;

