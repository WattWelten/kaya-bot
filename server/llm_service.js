const axios = require('axios');
const costTracker = require('./services/cost_tracker');

/**
 * KAYA LLM Service - OpenAI Integration
 * 
 * Dieser Service integriert OpenAI f√ºr intelligente Antworten
 * mit Fallback auf lokale Templates bei Fehlern.
 */

class LLMService {
    constructor() {
        this.openaiApiKey = process.env.OPENAI_API_KEY;
        this.openaiApiUrl = 'https://api.openai.com/v1/chat/completions';
        this.model = 'gpt-4o-mini'; // Kostenoptimiertes Modell
        this.maxTokens = 500;
        this.temperature = 0.7;
        
        // Circuit Breaker f√ºr Fehlerbehandlung
        this.circuitBreaker = {
            isOpen: false,
            failureCount: 0,
            lastFailureTime: 0,
            timeout: 60000 // 1 Minute
        };
        
        console.log('ü§ñ LLM Service initialisiert (OpenAI aktiviert)');
    }
    
    /**
     * Generiert intelligente Antwort mit OpenAI
     * 
     * @param {string} query - Die Benutzeranfrage
     * @param {object} context - Kontext (Persona, Intention, etc.)
     * @returns {Promise<object>} - {response: string, success: boolean}
     */
    async generateResponse(query, context = {}) {
        try {
            // Circuit Breaker pr√ºfen
            if (this.circuitBreaker.isOpen) {
                if (Date.now() - this.circuitBreaker.lastFailureTime > this.circuitBreaker.timeout) {
                    this.circuitBreaker.isOpen = false;
                    this.circuitBreaker.failureCount = 0;
                    console.log('üîß Circuit Breaker: Geschlossen, versuche erneut');
                } else {
                    console.log('‚ö†Ô∏è Circuit Breaker: Offen, Fallback aktiviert');
                    return { response: null, success: false, reason: 'circuit_breaker' };
                }
            }
            
            // OpenAI API Call
            const response = await axios.post(
                this.openaiApiUrl,
                {
                    model: this.model,
                    messages: this.buildMessages(query, context),
                    max_tokens: this.maxTokens,
                    temperature: this.temperature,
                    top_p: 1,
                    frequency_penalty: 0,
                    presence_penalty: 0
                },
                {
                    headers: {
                        'Authorization': `Bearer ${this.openaiApiKey}`,
                        'Content-Type': 'application/json'
                    },
                    timeout: 10000 // 10 Sekunden Timeout
                }
            );
            
            // Erfolgreiche Antwort
            this.circuitBreaker.isOpen = false;
            this.circuitBreaker.failureCount = 0;
            
            const aiResponse = response.data.choices[0].message.content;
            
            // Kosten tracken
            const inputTokens = response.data.usage.prompt_tokens;
            const outputTokens = response.data.usage.completion_tokens;
            costTracker.trackOpenAI(inputTokens, outputTokens);
            
            console.log('‚úÖ OpenAI Antwort erhalten:', aiResponse.substring(0, 100));
            
            return {
                response: aiResponse,
                success: true,
                usage: response.data.usage
            };
            
        } catch (error) {
            // Fehlerbehandlung
            this.handleError(error);
            return {
                response: null,
                success: false,
                reason: error.message
            };
        }
    }
    
    /**
     * Baut die Messages f√ºr OpenAI
     * 
     * @param {string} query - Die Benutzeranfrage
     * @param {object} context - Kontext
     * @returns {Array} - Messages f√ºr OpenAI
     */
    buildMessages(query, context) {
        const systemPrompt = this.buildSystemPrompt(context);
        
        return [
            {
                role: 'system',
                content: systemPrompt
            },
            {
                role: 'user',
                content: query
            }
        ];
    }
    
    /**
     * Erstellt System-Prompt f√ºr KAYA
     * 
     * @param {object} context - Kontext (Persona, Intention, etc.)
     * @returns {string} - System-Prompt
     */
    buildSystemPrompt(context) {
        const { persona, emotionalState, urgency, language = 'german' } = context;
        
        let prompt = `Du bist KAYA, wie die geduldige und kompetente Mitarbeiterin am Empfang im B√ºrgerb√ºro des Landkreises Oldenburg ‚Äì nur digital. Du hilfst so, wie man es dort am Schalter erlebt: zugewandt, konkret und ohne Redeschaum.

**Dein Auftreten:**
- Rede direkt und warm: "Sie" ist okay, aber "Du/Dich" ist hier allt√§glich und passt besser
- Norddeutsch und unkompliziert: "Moin!" und nat√ºrliche, kurze S√§tze
- Keine Aufz√§hlungslisten im Text ‚Äì lieber 2‚Äì3 klare S√§tze im Dialog

**Dein Vorgehen:**
- Kurze Nachfrage: "Brauchen Sie das heute oder hat's Eile?"
- 2‚Äì3 konkrete Schritte, die der B√ºrger JETZT machen kann
- Fr√ºhzeitig Hinweise zu Kosten oder Wartezeiten
- Bei Unsicherheit: "M√∂chten Sie kurz anrufen? 04431 85-0"

**Bei Problemen:**
- Unsicherheit aufgreifen und sachlich beruhigen
- Zeitdruck erkennen ‚Äì dann ruhig und zielf√ºhrend reagieren
- Was du verstanden hast, kurz zusammenfassen
- Abschluss: wenn passend, kurz verbindlich abschlie√üen

**Beispiel:**
"Moin! Meldebescheinigung ‚Äì klar. Eilbedarf oder normal?
‚úì Heute? Pers√∂nlich im Amt, 04431 85-0 f√ºr Termin
‚úì Normal? Online beantragen, Link direkt.
Was passt zu Ihnen?"`;

        // Persona-spezifische Anpassungen
        if (persona && persona.persona) {
            prompt += `\n\nPERSONA KONTEKT: Der B√ºrger ist ${persona.persona}`;
        }
        
        // Emotionale Zust√§nde
        if (emotionalState && emotionalState.state) {
            const emotionPrompts = {
                frustrated: 'Der B√ºrger ist frustriert - sei besonders empathisch und l√∂sungsorientiert',
                anxious: 'Der B√ºrger ist unsicher - sei beruhigend und unterst√ºtzend',
                positive: 'Der B√ºrger ist motiviert - sei enthusiastisch und best√§rkend',
                neutral: 'Der B√ºrger ist neutral - sei professionell und hilfreich'
            };
            prompt += `\nEMOTIONALER ZUSTAND: ${emotionPrompts[emotionalState.state] || ''}`;
        }
        
        // Dringlichkeit
        if (urgency && urgency.level === 'critical') {
            prompt += `\n\nDRINGLICHKEIT: KRITISCH - Biete sofort Hilfe (Telefonnummer, Termine)`;
        }
        
        prompt += `\n\nANTWORTE JETZT auf die Anfrage. Sei konkret, hilfreich und norddeutsch.`;
        
        return prompt;
    }
    
    /**
     * Fehlerbehandlung mit Circuit Breaker
     * 
     * @param {Error} error - Der Fehler
     */
    handleError(error) {
        this.circuitBreaker.failureCount++;
        this.circuitBreaker.lastFailureTime = Date.now();
        
        // Bei 3 Fehlern: Circuit Breaker √∂ffnen
        if (this.circuitBreaker.failureCount >= 3) {
            this.circuitBreaker.isOpen = true;
            console.error('üî¥ Circuit Breaker: GE√ñFFNET nach 3 Fehlern');
        }
        
        // Log Fehler
        if (error.response) {
            console.error('‚ùå OpenAI API Fehler:', error.response.status, error.response.data);
        } else if (error.request) {
            console.error('‚ùå OpenAI API Fehler: Keine Antwort vom Server');
        } else {
            console.error('‚ùå OpenAI API Fehler:', error.message);
        }
    }
    
    /**
     * Pr√ºft ob Service verf√ºgbar ist
     * 
     * @returns {boolean}
     */
    isAvailable() {
        return !!this.openaiApiKey && !this.circuitBreaker.isOpen;
    }
    
    /**
     * Gibt Status zur√ºck
     * 
     * @returns {object}
     */
    getStatus() {
        return {
            available: this.isAvailable(),
            circuitBreakerOpen: this.circuitBreaker.isOpen,
            failureCount: this.circuitBreaker.failureCount,
            hasApiKey: !!this.openaiApiKey
        };
    }
}

module.exports = LLMService;

